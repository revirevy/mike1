{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "263eb813-da45-48cf-9a8f-9da76c18e470"
   },
   "source": [
    "# Project 2\n",
    "## Step 1: Exploring your data.\n",
    "\n",
    "##### Load your data in using Pandas and start to explore. Save all of your early exploration code here and include in your final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michaelmainzer/Documents/GA/DSI/mike1/01-projects/notebooks/project-2\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b733d2fe-6d33-41dd-a3fc-5dfe9d71d91f"
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ../assets/02-project2-assets/billboard.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-45230176400f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#'/Users/michaelmainzer/Documents/GA/DSI/mike1/01-projects/assets/02-project2-assets/billboard.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../assets/02-project2-assets/billboard.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File ../assets/02-project2-assets/billboard.csv does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "#'/Users/michaelmainzer/Documents/GA/DSI/mike1/01-projects/assets/02-project2-assets/billboard.csv'\n",
    "bData = pd.read_csv('../assets/02-project2-assets/billboard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bData['date.entered'] = pd.to_datetime(bData['date.entered'])\n",
    "bData['date.peaked'] = pd.to_datetime(bData['date.peaked'])\n",
    "bData['x1st.week'] = bData['x1st.week'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bData['days.to.peak'] = (bData['date.peaked'] - bData['date.entered']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalWeeks = []\n",
    "\n",
    "for i in range(len(bData)):\n",
    "    totalWeeks.append(0)\n",
    "    for j in range(7,83):\n",
    "        if bData.iloc[i,j] >= 1:\n",
    "            totalWeeks[i] += 1\n",
    "\n",
    "bData['total.weeks'] = totalWeeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "888b6223-3bb4-4d91-b753-4867a3a1b281"
   },
   "source": [
    "### Step 2: Clean your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8a273328-6d9f-4dfc-88f8-a0c18e4d7f90"
   },
   "source": [
    "##### Do some rudimentary cleaning. Rename any columns that are poorly named, shorten any strings that may be too long, fill in any missing values. Explain your rationale for the way you choose to \"impute\" the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "604ee5d7-10ed-4d14-9f86-16a6b240c00d"
   },
   "source": [
    "##### Using Pandas' built in `melt` function, pivot the weekly ranking data to be long rather than wide. As a result, you will have removed the 72 'week' columns and replace it with two: Week and Ranking. There will now be multiple entries for each song, one for each week on the Billboard rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "bf0161ca-0fcb-4883-a216-93fd7ffa6456"
   },
   "outputs": [],
   "source": [
    "df = pd.melt(bData, id_vars = ['year', 'artist.inverted', 'track', 'time', 'genre', 'date.entered', 'date.peaked', \n",
    "                               'days.to.peak', 'total.weeks'], var_name='Week', value_name='Rank')\n",
    "\n",
    "df.columns = ['Year','Artist','Track','Length','Genre','Date Entered Rankings','Date Peaked','Days to Peak',\n",
    "              'Total Weeks','Week','Rank']\n",
    "df1 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.Week = df1['Week'].apply(lambda x: x.lstrip('x').rstrip('rdndthst.week'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data dictionary goes here.\n",
    "df1.Week = df1['Week'].apply(lambda x: int(x))\n",
    "df1.to_csv('../assets/02-project2-assets/billboard1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTracks = df1.groupby(df1['Track']).size()\n",
    "dfTracks.to_csv('../assets/02-project2-assets/track_staying power.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genreRank = df1['Rank'].groupby([df1['Genre']]).mean()\n",
    "genreRank.to_csv('../assets/02-project2-assets/genre_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genreWeeks = df1['Total Weeks'].groupby([df1['Genre']]).mean()\n",
    "genreWeeks.to_csv('../assets/02-project2-assets/genre_weeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genreDaystoPeak = df1['Days to Peak'].groupby([df1['Genre']]).mean()\n",
    "genreDaystoPeak.to_csv('../assets/02-project2-assets/genre_daystopeak.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topTenOverTime = df1.loc[df1['Rank'] <= 10]\n",
    "\n",
    "topTenOverTime.to_csv('../assets/02-project2-assets/top_ten_over_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topFiveOverTime = df1.loc[df1['Rank'] <= 5]\n",
    "\n",
    "topFiveOverTime.to_csv('../assets/02-project2-assets/top_five_over_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdf = df1.loc[df1['Rank'] < 2]\n",
    "del newdf['Week']\n",
    "topHits = newdf.drop_duplicates()\n",
    "topHits.to_csv('../assets/02-project2-assets/topHits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del topTenOverTime['Week']\n",
    "del topTenOverTime['Rank']\n",
    "topTen = topTenOverTime.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable | Description | Variable Type\n",
    "--|--|--\n",
    "Year | The year the song was released | Integer\n",
    "Artist | The song's artist | Object\n",
    "Track | The song's title | Object\n",
    "Length | The song's length, in minutes and seconds | Object\n",
    "Genre | The song's genre | Object\n",
    "Date Entered Rankings | Year, month, and day the song entered the Billboard Top 100 | Datetime\n",
    "Date Peaked | Date the song reached it's highest rank while in the Billboard Top 100 | Datetime\n",
    "Days to Peak | Amount of days it took for the song to reach that peack | Integer\n",
    "Total Weeks | Number of weeks the song remained in the Billboard Top 100 | Integer\n",
    "Week | Lists each week of the rankings from 1 - 64 | Integer\n",
    "Rank | Provides correspronding rank of each song at that particular week | Float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "2023c5a8-1f4e-4d83-9a52-c41a5090af74"
   },
   "source": [
    "## Step 3: Visualize your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visual below tells us a few things about the data. First, each bubble represents a single song, and all songs are arranged by their genre, indicated by the color assigned in the legend. Finally, the staying power of each song is noted by the size of the bubble - the larger the bubble, the longer the song remained in the Top 100.\n",
    "\n",
    "Clearly, we can see that Rock is the most popular within the entire data set. Not only does it contain the most songs, it also contains the most songs that remained in the charts for many weeks.\n",
    "\n",
    "Another interesting thing to note is the grouping of country songs. While there were quite a few country songs represented at some point, only one, 'Amazed' seemed to have any lasting popularity. In the future, a record company involved in producing country songs may seek to emulate trends within 'Amazed' in an attempt to replicate its popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JB perfect synopsis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='../assets/02-project2-assets/visuals-billboard1/Bubble Map_Total Weeks for Tracks.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e1b81214-9b26-4735-8c1b-4482e948b355"
   },
   "outputs": [],
   "source": [
    "ax = sns.factorplot(x=\"Week\", y=\"Rank\", hue=\"Genre\", data=df1, kind=\"point\", legend_out=False,size=8, aspect=4)\n",
    "legend = plt.legend(fontsize=\"x-large\")\n",
    "plt.title('Change in Rank by Genre\\n', fontsize = 50)\n",
    "plt.xlabel(\"Week\", fontsize=30)\n",
    "plt.ylabel(\"Rank\", fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have a scatter plot that shows the change in rank for all songs within their genres, spanning the full 64 weeks in which the list of songs had a record within the rankings. Songs are contained within the lines for each genre, which are color coded according to the legend. \n",
    "\n",
    "As we can see, rock and country last the longest, but as we can infer from the preceding visual, the tail end of the Country line is a single song: 'Amazed.' To the left of the plot, we see that Latin, Electronica, Jazz, and Reggae songs all have quick exits after making an initial dip into the rankings.\n",
    "\n",
    "The most thought provoking thing about this plot is illustrated more clearly in the chart below, which is the same, but formulated as an area chart. Clearly, the chart shows us a steep decline in songs present by the 20th week. It looks like songs around 50 or lower (meaning towards 100) by the 19th week were promptly pulled from the rankings entirely, rather than being allowed to gradually fade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='../assets/02-project2-assets/visuals-billboard1/Area Chart_Rank by Genre.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see the initial scatterplot above, except each genre is separated into its own plot so we can differentiate trends that may be partial to songs in a particular genre.\n",
    "\n",
    "Nearly every genre follows a similar pattern, with the bulk of its songs exiting the ranks entirely before the 20th week of records. Songs that were in the Top 50 by that week gradually faded out, as we can see by the tails.\n",
    "\n",
    "Looking closely at each individual plot confirms that there is something significant about the 20 Week mark and being within the Top 50. Songs that make it to Week 20 within the Top 50 stay on. However, after that 20th week, as soon as they rise above Top 50, they vanish from the rankings entirely, like with Rap, Pop, and Latin. \n",
    "\n",
    "This suggests that the music industry, and in this case it must be radio stations, as they control what's played on their stations, must see little use for keeping a song in their rotation if after five months there are 50 songs more popular than it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df1, col=\"Genre\")  \n",
    "g.map(plt.scatter, \"Week\", \"Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have a bar chart that shows us the average amount of days it took for a song to hit its personal peak, grouped again by genre. The lowest value is, of course, Jazz music, and the longest average was Rock, followed closely by Latin. Generally, most other genres had high averages as well.\n",
    "\n",
    "While the bar graph may suggest that Latin, Electronica, or Gospel music stayed on the charts for quite a while, let's remember from our first visualization, that there were only 9 Latin songs to begin with, out of a total of 317 songs, and only a handful within Electronica or Gospel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(\"Week\", \"Rank\", data=tips, scatter=False, color=\".1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='../assets/02-project2-assets/visuals-billboard1/Bar Chart_Days to Peak by Genre.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "top_genres = bData.genre.value_counts()\n",
    "top_genres.plot(kind='barh', color = 'c')\n",
    "plt.ylabel('Genre')\n",
    "plt.xlabel('No. of Songs')\n",
    "plt.title('Top 10 Songs by Genre in Billboard Top 100\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These bar charts reveal the total share of the Top 100 by genre a bit more clearly than above. As we can see, Rock has nearly twice as many songs as Country, the next most popular genre.\n",
    "\n",
    "Going slighlty deeper into the rankings, below we have a pie chart that shows the share of the Top 10 songs by genre. Reggae, Jazz, and Gospel never had a song enter the Top 10 at any point in the 73 weeks of collection, so they are no longer present.\n",
    "\n",
    "Probably the most interesting thing about this is Country. Again, as some of the visuals above illustrate, Country songs clearly have staying power, and there are many that are popular enough to remain in the Top 100 for quite a while. Our bar chart above and our initial visual shows us they're the second most popular overall. That being said, any song that climbs very high in the rankings is an outlier for the genre. Of all songs that at some point were in the Top 10, Rock clearly dominates, and Country only had 1 out of over 70 entries, 'Amazed,' crack that upper echelon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='../assets/02-project2-assets/visuals-billboard2/Pie Chart_Top 10.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see the amount of days it takes a typical song in a genre to reach its peak ranking by the number of weeks it's been in the rankings. Clearly, the longer it's been in the rankings, the longer it takes a song to reach its personal peak. However, it would be interesting to split this line into 2 groups, one in the Top 50 and the other in the bottom 50. We could then see the impact of making the Top 50, where a song may be allowed more time to continue climbing the rankings as opposed to just being forced out.\n",
    "\n",
    "It would also be helpful to track this alongside earnings from record sales. We could then take a song in the Country genre that remained in the Top 50 for a long time, but never quite got into the Top 10, and compare that to a Pop or Rock song that only had a brief amount of time in the Top 10, and then dropped off quickly. The Country song may have been in the rankings longer, but did it result in more album purchases? The answer to this question could assist record labels in making decisions about how it markets its songs, and for how long, depending on this window of opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image(filename='../assets/02-project2-assets/visuals-billboard2/Days to Peak by Weeks.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8401c631-245b-4560-8971-25cb2406c2ab"
   },
   "source": [
    "## Step 4: Create a Problem Statement.\n",
    "\n",
    "##### Having explored the data, come up with a problem statement for this data set. You can feel free to introduce data from any other source to support your problem statement, just be sure to provide a link to the origin of the data. Once again- be creative!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a 20 week threshold for a song of any genre to remain relevant in the Billboard Top 100, otherwise that song will be dropped from the rankings entirely. This gives a particular song a relatively short period of time to gain traction with audiences, and it may force artists and their labels to speed up or slow down production of music in the future if they find their songs don't have much longevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a0ff30a0-48be-4851-9ec3-4ce8ece08a67"
   },
   "source": [
    "## Step 5: Brainstorm your Approach.\n",
    "##### In bullet-list form, provide a proposed approach for evaluating your problem statement. This can be somewhat high-level, but start to think about ways you can massage the data for maximum efficacy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "9d772c7b-61e0-4bc4-bb1a-f3d43ba54862"
   },
   "source": [
    "* First, we need an understanding of industry practices during this period. How exactly are radio stations making their decisions to discontinue playing songs? Do they receive listener input? And if so, in what form? Is it even radio stations that decided to drop a song, or were record labels making those decisions?\n",
    "\n",
    "* We need to find some industry norming on genre labeling. Looking at this data on the surface, it's cleark that a typical Rock song had a greater chance of making its way ot the top of the rankings at some point. However, artists like Destiny's Child and Creed each have songs categorized as Rock, yet their music isn't similar. Could a record label use Rock's popularity and simply tag it to a song, giving it a greater chance of gaining traction in the rankings?\n",
    "\n",
    "* Records of earnings from individual songs would be helpful in determining the extent to which these rankings impacted consumer purchases. We could then see if being in the Top 10 for a short period of time was more valuable than being in the middle of the pack for a very long time. This was in a media environment where if a listener wanted to own a particular song, they had to purchase the entire album it came on. If we could attach song rankings to album sales, we could determine if a single hit song was enough of an incentive for a consumer to take a chance on an entire album of songs or not.\n",
    "\n",
    "* Similar rankings data from the most recent couple of years would be useful for a comparison that could more effectively determine the nature of popularity for individual songs. At the time of our current data set, 1999 - 2000, media consumption was largely industry controlled. A typical listener didn't have access to any songs, and could either choose to listen to a song on a radio station, or change to a different radio station if they didn't care for that song. If we could compare that process to today's environment, where a listener can simply use the internet to listen to whichever song they choose, regardless of what radio stations or record labels place in front of them, we could gain a clearer perspective as to what factors contribute to a song's lasting popularity. Will a song last for dozens of weeks on end in today's environmnet? Or will the limitless choices force artists to constantly produce mroe songs to keep up with demand? Can record labels survive today's environment using a model similar to our current data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "aee61cbf-dfe9-40d3-bfef-772a60bed757"
   },
   "source": [
    "## BONUS: The Content Managers working for the Podcast Publishing Company have recognized you as a thought leader in your field. They've asked you to pen a white paper (minimum 500 words) on the subject of 'What It Means To Have Clean Data'. This will be an opinion piece read by a wide audience, so be sure to back up your statements with real world examples or scenarios.\n",
    "\n",
    "##### Hint: To get started, look around on the internet for articles, blog posts, papers, youtube videos, podcasts, reddit discussions, anything that will help you understand the challenges and implications of dealing with big data. This should be a personal reflection on everything you've learned this week, and the learning goals that have been set out for you going forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "28deb393-c994-47bc-87d2-035741ce527c"
   },
   "source": [
    "Score | 24/24\n",
    "----- | ------\n",
    "Identify: Problem Statement / Hypothesis\t| 3\n",
    "Identify: Risks & Assumptions\t\t\t\t| 3\n",
    "Acquire: Import Data Using Pandas\t\t\t| 3\n",
    "Parse: Perform EDA Using Pandas\t\t\t\t| 3\n",
    "Mine: Plot Data & Generate Visuals\t\t\t| 3\n",
    "Mine: Determine Correlations\t\t\t\t| 3\n",
    "Refine: Evaluate Findings\t\t\t\t    | 3\n",
    "Present: Describe Results in Blog Post\t\t| 3\n",
    "Bonus! Present: Write a short White Paper\t| 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
