{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is just my efforts to play around with beautiful soup\n",
    "\n",
    "\n",
    "#results = soup.find_all('div', {'class': 'row result'})\n",
    "#print results[1].find('span', {'class': 'company'}).text\n",
    "#print results[1].find('a', {'data-tn-element': 'jobTitle'}).text\n",
    "#print results[1].find('span', {'class': 'location'}).text\n",
    "#print results[1].find('td', {'class': 'snip'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#salary = []\n",
    "#jobTitle = []\n",
    "#company = []\n",
    "#location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def findLocation(url):\n",
    "#    soup = BeautifulSoup(requests.get(url).text)\n",
    "#    for loc in soup.findAll('span', {'class': 'location'}):\n",
    "#        location.append(loc.text.strip())\n",
    "\n",
    "#def findCompany(url):\n",
    "#    soup = BeautifulSoup(requests.get(url).text)\n",
    "#    for loc in soup.findAll('span', {'class': 'company'}):\n",
    "#        company.append(loc.text.strip())\n",
    "        \n",
    "#def findSalary(url):\n",
    "#    soup = BeautifulSoup(requests.get(url).text)\n",
    "#    for sal1, sal2 in zip(soup.find_all(\"td\", class_=\"snip\"), soup.find_all(\"span\", class_=\"location\")):\n",
    "#        child = sal1.findChild(\"nobr\")\n",
    "#        sibling = sal2.findNextSibling(\"div\")\n",
    "#        if child != None:\n",
    "#            salary.append(child.text)\n",
    "#        elif sibling != None:\n",
    "#            salary.append(sibling.text)\n",
    "#        else:\n",
    "#            salary.append('NaN')\n",
    "\n",
    "#def findLocation(url):\n",
    "#    soup=BeautifulSoup(requests.get(url).text)\n",
    "#    for locale in soup.find_all(\"span\", {\"class\": \"location\"}):\n",
    "#        locale1 = locale.text.strip()\n",
    "#        if locale1 != None:\n",
    "#            location.append(locale1)\n",
    "#        else:\n",
    "#            location.append('Nan')\n",
    "#location = [loc.text.strip for loc in soup.findAll('span', {'class': 'location'})]\n",
    "\n",
    "#def findCompany(url):\n",
    "#    soup=BeautifulSoup(requests.get(url).text)\n",
    "#    for comp in soup.find_all(\"span\", {\"class\": \"company\"}):\n",
    "#        comp1 = comp.text.strip()\n",
    "#        if comp1 != None:\n",
    "#            company.append(comp1)\n",
    "#        else:\n",
    "#            company.append('NaN')\n",
    "\n",
    "    \n",
    "#company = [loc.get_text(strip=True) for loc in soup.findAll('span', {'class': 'company'})]\n",
    "\n",
    "#def findJobTitle(url):\n",
    "#    jobTitle = [loc.get_text(strip=True) for loc in soup.findAll('a', {'data-tn-element': 'jobTitle'})]\n",
    "\n",
    "#def findJobTitle(url):\n",
    "#    soup=BeautifulSoup(requests.get(url).text)\n",
    "#    for job in soup.find_all(\"a\", {\"data-tn-element\": \"jobTitle\"}):\n",
    "#        job1 = job.text.strip()\n",
    "#       if job1 != None:\n",
    "#            jobTitle.append(job1)\n",
    "#        else:\n",
    "#            jobTitle.append('NaN')\n",
    "\n",
    "\n",
    "#def findSalary(url):\n",
    "#    salary = [loc.get_text(strip=True) for loc in soup.findAll('td', {'class': 'snip'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#max_results_per_city = 100\n",
    "\n",
    "#for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Atlanta', 'Washington+DC', \n",
    "#                 'Minneapolis', 'Denver', 'Seattle', 'Boston', 'Los+Angeles', 'Phoenix']):\n",
    "#    \n",
    "#    for start in range(0, max_results_per_city, 10):\n",
    "#        url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=\"+ city + \"&start=\" +str(start)\n",
    "#        findLocation(url_template)\n",
    "#        findCompany(url_template)\n",
    "#        findJobTitle(url_template)\n",
    "#        findSalary(url_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print len(location)\n",
    "#print len(company)\n",
    "#print len(jobTitle)\n",
    "#print len(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "#df = pd.DataFrame({'location': location, 'company': company, 'jobTitle': jobTitle, 'salary': salary})\n",
    "#df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
