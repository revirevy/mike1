{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs Lab\n",
    "In this lab we will practice using APIs to retrieve and store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports at the top\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from imdbpie import Imdb\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb = Imdb()\n",
    "imdb = Imdb(anonymize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.a Get bottom and top movies\n",
    "\n",
    "The Internet Movie Database contains data about movies. Unfortunately it does not have a public API.\n",
    "\n",
    "The page http://www.imdb.com/chart/top contains the list of the top worst 100 movies of all time. Retrieve the page using the requests library and then parse the html to obtain a list of the `movie_ids` for these movies. You can parse it with regular expression or using a library like `BeautifulSoup`.\n",
    "\n",
    "**Hint:** movie_ids look like this: `tt2582802`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#So this function gets a list of all 100 movies IDs.\n",
    "#However, IMDB.com doesn't like people getting all of their data very easily, so we'll just use this page to get the IDs\n",
    "#So this function doesn't iterate through pages, as all movies in the Bottom 100 are on a single page.\n",
    "#It takes their unique IDs that are encoded in the HTML, and puts them in a list, called 'entries\n",
    "def get_entries(site):\n",
    "    response = requests.get(site)\n",
    "    html = response.text\n",
    "    entries = re.findall(\"<a href.*?/title/(.*?)/\", html) #Wrong regex\n",
    "    return list(set(entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottomEntries = get_entries('http://www.imdb.com/chart/bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topEntries = get_entries('http://www.imdb.com/chart/top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.b Get bottom and top movies data\n",
    "\n",
    "Although the Internet Movie Database does not have a public API, an open API exists at http://www.omdbapi.com.\n",
    "\n",
    "Use this API to retrieve information about each of the 100 movies you have extracted in the previous step.\n",
    "- Check the documentation of omdbapi.com to learn how to request movie data by id\n",
    "- Define a function that returns a python object with all the information for a given id\n",
    "- Iterate on all the IDs and store the results in a list of such objects\n",
    "- Create a Pandas Dataframe from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now that we have the 250 IDs, we need a way to search omdapi (which has gathered all data for each IMDB movie in a \n",
    "#nice little JSON tree). \n",
    "\n",
    "#So we need to scrape each movie's JSON tree with Beautiful soup\n",
    "#Just like with indeed.com, it's going to use omdabpi's search engine 250 times, once for each id in the entries list\n",
    "#from above. After it searches a movie id in the lsit above, it will scrape its JSON tree.\n",
    "def get_entry(entry):\n",
    "    res = requests.get('http://www.omdbapi.com/?i='+entry)\n",
    "    if res.status_code != 200:\n",
    "        print entry, res.status_code\n",
    "    else:\n",
    "        print '.',\n",
    "    try:\n",
    "        j = json.loads(res.text)\n",
    "    except ValueError:\n",
    "        j = None\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "#So you're going to repreat the function above for every item(movie id) in the 'entries' list\n",
    "#It returns a dictionary that can then be turned into a dataframe\n",
    "bottomEntriesDictList = [get_entry(e) for e in bottomEntries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we turn the JSON file for each of th 100 movies into a dataframe\n",
    "bottom100 = pd.DataFrame(bottomEntriesDictList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "#So you're going to repreat the function above for every item(movie id) in the 'entries' list\n",
    "#It returns a dictionary that can then be turned into a dataframe\n",
    "topEntriesDictList = [get_entry(e) for e in topEntries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we turn the JSON file for each of th 100 movies into a dataframe\n",
    "top250 = pd.DataFrame(topEntriesDictList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.c Get gross data\n",
    "\n",
    "The OMDB API is great, but it does not provide information about Gross Revenue of the movie. We'll revert back to scraping for this.\n",
    "\n",
    "- Write a function that retrieves the gross revenue from the entry page at imdb.com\n",
    "- The function should handle the exception of when the page doesn't report gross revenue\n",
    "- Retrieve the gross revenue for each movie and store it in a separate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There is still some information we would want, but OMDb API does not provide\n",
    "#So, we have to go back to imdb.com to scrape the gross revenue for each movie\n",
    "#This function will ultimately search for each movie by their id in the entries list, and scrape the gross revenue into\n",
    "#a new list called 'grosses\n",
    "\n",
    "def get_gross(entry): #define the function\n",
    "    response = requests.get('http://www.imdb.com/title/'+entry) #This will generate a request from the page for an entry\n",
    "    html = response.text\n",
    "    try:\n",
    "        gross_list = re.findall(\"Gross:</h4>[ ]*\\$([^ ]*)\", html) #This will create a list with the value after the word 'Gross'\n",
    "        gross = int(gross_list[0].replace(',', '')) #This creates a new value by convertinf the above to an integer and eliminating commas\n",
    "        return gross\n",
    "    except Exception as ex:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottomGrosses = [(e, get_gross(e)) for e in bottomEntries]#Repeat the function above for each id in the entries list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topGrosses = [(e, get_gross(e)) for e in topEntries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottomGrosses = pd.DataFrame(bottomGrosses, columns=['imdbID', 'gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topGrosses = pd.DataFrame(topGrosses, columns=['imdbID', 'gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottomGrosses[\"gross\"] = bottomGrosses[\"gross\"].fillna(bottomGrosses[\"gross\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topGrosses[\"gross\"] = topGrosses[\"gross\"].fillna(topGrosses[\"gross\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Data munging\n",
    "\n",
    "- Now that you have movie information and gross revenue information, let's clean the two datasets.\n",
    "- Check if there are null values. Be careful they may appear to be valid strings.\n",
    "- Convert the columns to the appropriate formats. In particular handle:\n",
    "    - Released\n",
    "    - Runtime\n",
    "    - year\n",
    "    - imdbRating\n",
    "    - imdbVotes\n",
    "- Merge the data from the two datasets into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanData(df, df1):\n",
    "    movieType = []\n",
    "    df.drop(['Actors','Awards','Country','Director','Genre','Language','Metascore',\n",
    "             'Plot','Poster','Rated','Released','Response','Type','Writer'], axis =1 ,inplace=True)\n",
    "    df = df[df.Runtime != 'N/A']\n",
    "    for row in ['Runtime']:\n",
    "        df['Runtime'] = df['Runtime'].str.rstrip('min').astype(float)\n",
    "    for row in ['Year']:\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "    for row in ['imdbRating']:\n",
    "        df['imdbRating'] = df['imdbRating'].astype(float)\n",
    "    for row in ['imdbVotes']:\n",
    "        df['imdbVotes'] = df['imdbVotes'].replace(',','',regex=True).astype(float)\n",
    "    for row in df['imdbRating']:\n",
    "        if row <= 3:\n",
    "            movieType.append(0)\n",
    "        else:\n",
    "            movieType.append(1)\n",
    "    df['movieType'] = movieType\n",
    "    df = df.rename(columns = {'imdbID'      :'imdbID',\n",
    "                                  'Title'       :'title',\n",
    "                                  'Year'        :'year',\n",
    "                                  'Runtime'     :'runtime',\n",
    "                                  'imdbVotes'   :'imdbVotes',\n",
    "                                  'imdbRating'  :'imdbRating',\n",
    "                                  'movieType'   :'movieType'})\n",
    "    df = df[['imdbID', 'title', 'year', 'runtime', 'imdbVotes', 'imdbRating', 'movieType']]\n",
    "    df = pd.merge(df, df1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "top250 = cleanData(top250, topGrosses)\n",
    "bottom100 = cleanData(bottom100, bottomGrosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>movieType</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>2014</td>\n",
       "      <td>107.0</td>\n",
       "      <td>384504.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>13092000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0047478</td>\n",
       "      <td>Seven Samurai</td>\n",
       "      <td>1954</td>\n",
       "      <td>207.0</td>\n",
       "      <td>226364.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "      <td>269061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0082971</td>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>1981</td>\n",
       "      <td>115.0</td>\n",
       "      <td>653557.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>242374454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0050212</td>\n",
       "      <td>The Bridge on the River Kwai</td>\n",
       "      <td>1957</td>\n",
       "      <td>161.0</td>\n",
       "      <td>147591.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>27200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0848228</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>143.0</td>\n",
       "      <td>980989.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1</td>\n",
       "      <td>623279547.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID                         title  year  runtime  imdbVotes  \\\n",
       "0  tt2582802                      Whiplash  2014    107.0   384504.0   \n",
       "1  tt0047478                 Seven Samurai  1954    207.0   226364.0   \n",
       "2  tt0082971       Raiders of the Lost Ark  1981    115.0   653557.0   \n",
       "3  tt0050212  The Bridge on the River Kwai  1957    161.0   147591.0   \n",
       "4  tt0848228                  The Avengers  2012    143.0   980989.0   \n",
       "\n",
       "   imdbRating  movieType        gross  \n",
       "0         8.5          1   13092000.0  \n",
       "1         8.7          1     269061.0  \n",
       "2         8.5          1  242374454.0  \n",
       "3         8.2          1   27200000.0  \n",
       "4         8.1          1  623279547.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top250.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>movieType</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0118665</td>\n",
       "      <td>Baby Geniuses</td>\n",
       "      <td>1999</td>\n",
       "      <td>97.0</td>\n",
       "      <td>19205.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.714196e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0058548</td>\n",
       "      <td>Santa Claus Conquers the Martians</td>\n",
       "      <td>1964</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8735.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>9.953230e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0089280</td>\n",
       "      <td>Hobgoblins</td>\n",
       "      <td>1988</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8416.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.953230e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0830861</td>\n",
       "      <td>A Fox's Tale</td>\n",
       "      <td>2008</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7203.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.953230e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0299930</td>\n",
       "      <td>Gigli</td>\n",
       "      <td>2003</td>\n",
       "      <td>121.0</td>\n",
       "      <td>41461.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.660084e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID                              title  year  runtime  imdbVotes  \\\n",
       "0  tt0118665                      Baby Geniuses  1999     97.0    19205.0   \n",
       "1  tt0058548  Santa Claus Conquers the Martians  1964     81.0     8735.0   \n",
       "2  tt0089280                         Hobgoblins  1988     88.0     8416.0   \n",
       "3  tt0830861                       A Fox's Tale  2008     85.0     7203.0   \n",
       "4  tt0299930                              Gigli  2003    121.0    41461.0   \n",
       "\n",
       "   imdbRating  movieType         gross  \n",
       "0         2.5          0  2.714196e+07  \n",
       "1         2.5          0  9.953230e+06  \n",
       "2         2.3          0  9.953230e+06  \n",
       "3         2.2          0  9.953230e+06  \n",
       "4         2.4          0  5.660084e+06  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250.to_csv('../../../../../01-projects/assets/06-project6-assets/data/top250.csv', encoding='utf8', index=False)\n",
    "bottom100.to_csv('../../../../../01-projects/assets/06-project6-assets/data/bottom100.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Text vectorization\n",
    "\n",
    "There are several columns in the data that contain a comma separated list of items, for example the Genre column and the Actors column. Let's transform those to binary columns using the count vectorizer from scikit learn.\n",
    "\n",
    "Append these columns to the merged dataframe.\n",
    "\n",
    "**Hint:** In order to get the actors name right, you'll have to modify the `token_pattern` in the `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250MovieIDs = top250.imdbID.values.tolist()\n",
    "bottom100MovieIDs = bottom100.imdbID.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250Reviews = []\n",
    "top250IDs = []\n",
    "for x in top250MovieIDs:\n",
    "    review = imdb.get_title_reviews(x, max_results=15)\n",
    "    for i in review:\n",
    "        top250IDs.append(x)\n",
    "        top250Reviews.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250ReviewData = pd.DataFrame({\"movieID\": top250IDs, \"reviews\": top250Reviews})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom100Reviews = []\n",
    "bottom100IDs = []\n",
    "for x in bottom100MovieIDs:\n",
    "    review = imdb.get_title_reviews(x, max_results=15)\n",
    "    for i in review:\n",
    "        bottom100IDs.append(x)\n",
    "        bottom100Reviews.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom100ReviewData = pd.DataFrame({\"movieID\": bottom100IDs, \"reviews\": bottom100Reviews})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "top250Tokens = [tokenizer.tokenize(review) for review in top250Reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250PosTokens = [nltk.tag.pos_tag(token) for token in top250Tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom100Tokens = [nltk.word_tokenize(review) for review in bottom100Reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom100PosTokens = [nltk.tag.pos_tag(token) for token in bottom100Tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next 5 cells will have to be repeated for bottom100 after you get top250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250AdjList = []\n",
    "for x in top250PosTokens:\n",
    "    # each x is either a list of (word, POS tag) tuples\n",
    "    for word, pos in x:\n",
    "        if pos in ['JJ', 'JJS', 'JJR']: # feel free to add any other tags you may be looking for\n",
    "            top250AdjList.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250CommonAdj= [a for a, b in Counter(top250AdjList).most_common(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'t</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>other</th>\n",
       "      <th>good</th>\n",
       "      <th>many</th>\n",
       "      <th>first</th>\n",
       "      <th>more</th>\n",
       "      <th>such</th>\n",
       "      <th>most</th>\n",
       "      <th>...</th>\n",
       "      <th>special</th>\n",
       "      <th>acting</th>\n",
       "      <th>main</th>\n",
       "      <th>funny</th>\n",
       "      <th>final</th>\n",
       "      <th>important</th>\n",
       "      <th>emotional</th>\n",
       "      <th>later</th>\n",
       "      <th>simple</th>\n",
       "      <th>strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: ['t, great, best, other, good, many, first, more, such, most, own, same, real, few, much, old, new, true, last, young, different, bad, classic, big, beautiful, whole, brilliant, original, greatest, better, only, second, top, wonderful, long, little, human, least, powerful, full, special, acting, main, funny, final, important, emotional, later, simple, strong]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 50 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe that places each descriptor as an index\n",
    "#We see that a top 50 adjective is the letter 't.' Not sure what the pos tagger is doing there, so we'll drop the col\n",
    "top250Descrip = pd.DataFrame(columns=top250CommonAdj)\n",
    "top250Descrip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we want a dataframe that joins the Review data (movieID, 15reviews each), from above with these descriptors\n",
    "top250Movies = pd.DataFrame(top250ReviewData)\n",
    "top250Movies = top250Movies.join(top250Descrip)\n",
    "#We see right now it's just filled with NaN values, so we'll populate the cells in the loop below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>reviews</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>other</th>\n",
       "      <th>good</th>\n",
       "      <th>many</th>\n",
       "      <th>first</th>\n",
       "      <th>more</th>\n",
       "      <th>such</th>\n",
       "      <th>...</th>\n",
       "      <th>special</th>\n",
       "      <th>acting</th>\n",
       "      <th>main</th>\n",
       "      <th>funny</th>\n",
       "      <th>final</th>\n",
       "      <th>important</th>\n",
       "      <th>emotional</th>\n",
       "      <th>later</th>\n",
       "      <th>simple</th>\n",
       "      <th>strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>http://switchingreels.com/2014/01/28/sundance-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>Taking the festival circuit by storm since its...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>After seeing Damien Chazelle's Whiplash - a fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>There is so many excellent great things to say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>I saw this about 24 hours ago at the Best of F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieID                                            reviews great best  \\\n",
       "0  tt2582802  http://switchingreels.com/2014/01/28/sundance-...   NaN  NaN   \n",
       "1  tt2582802  Taking the festival circuit by storm since its...   NaN  NaN   \n",
       "2  tt2582802  After seeing Damien Chazelle's Whiplash - a fi...   NaN  NaN   \n",
       "3  tt2582802  There is so many excellent great things to say...   NaN  NaN   \n",
       "4  tt2582802  I saw this about 24 hours ago at the Best of F...   NaN  NaN   \n",
       "\n",
       "  other good many first more such  ...   special acting main funny final  \\\n",
       "0   NaN  NaN  NaN   NaN  NaN  NaN  ...       NaN    NaN  NaN   NaN   NaN   \n",
       "1   NaN  NaN  NaN   NaN  NaN  NaN  ...       NaN    NaN  NaN   NaN   NaN   \n",
       "2   NaN  NaN  NaN   NaN  NaN  NaN  ...       NaN    NaN  NaN   NaN   NaN   \n",
       "3   NaN  NaN  NaN   NaN  NaN  NaN  ...       NaN    NaN  NaN   NaN   NaN   \n",
       "4   NaN  NaN  NaN   NaN  NaN  NaN  ...       NaN    NaN  NaN   NaN   NaN   \n",
       "\n",
       "  important emotional later simple strong  \n",
       "0       NaN       NaN   NaN    NaN    NaN  \n",
       "1       NaN       NaN   NaN    NaN    NaN  \n",
       "2       NaN       NaN   NaN    NaN    NaN  \n",
       "3       NaN       NaN   NaN    NaN    NaN  \n",
       "4       NaN       NaN   NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, let's drop that 't column\n",
    "top250Movies.drop(top250Movies.columns[[2]], axis=1, inplace=True)\n",
    "top250Movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDescriptors(df):\n",
    "    for c, col in enumerate(df.columns[2:]):\n",
    "        for r, row in enumerate(df.index):\n",
    "            reviewLower = df.loc[row,\"reviews\"].lower()\n",
    "            if (col in reviewLower):\n",
    "                df.loc[row,col] = 1\n",
    "            else:\n",
    "                df.loc[row,col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getDescriptors(top250Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>reviews</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>other</th>\n",
       "      <th>good</th>\n",
       "      <th>many</th>\n",
       "      <th>first</th>\n",
       "      <th>more</th>\n",
       "      <th>such</th>\n",
       "      <th>...</th>\n",
       "      <th>special</th>\n",
       "      <th>acting</th>\n",
       "      <th>main</th>\n",
       "      <th>funny</th>\n",
       "      <th>final</th>\n",
       "      <th>important</th>\n",
       "      <th>emotional</th>\n",
       "      <th>later</th>\n",
       "      <th>simple</th>\n",
       "      <th>strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>http://switchingreels.com/2014/01/28/sundance-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>Taking the festival circuit by storm since its...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>After seeing Damien Chazelle's Whiplash - a fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>There is so many excellent great things to say...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>I saw this about 24 hours ago at the Best of F...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieID                                            reviews great best  \\\n",
       "0  tt2582802  http://switchingreels.com/2014/01/28/sundance-...     1    0   \n",
       "1  tt2582802  Taking the festival circuit by storm since its...     1    1   \n",
       "2  tt2582802  After seeing Damien Chazelle's Whiplash - a fi...     1    1   \n",
       "3  tt2582802  There is so many excellent great things to say...     1    0   \n",
       "4  tt2582802  I saw this about 24 hours ago at the Best of F...     1    1   \n",
       "\n",
       "  other good many first more such  ...   special acting main funny final  \\\n",
       "0     1    1    0     0    1    0  ...         0      0    0     0     1   \n",
       "1     1    1    0     0    1    1  ...         1      0    0     0     0   \n",
       "2     1    1    0     0    0    0  ...         0      0    1     0     0   \n",
       "3     1    1    1     0    1    0  ...         0      1    0     0     0   \n",
       "4     1    1    0     1    1    1  ...         0      1    0     0     0   \n",
       "\n",
       "  important emotional later simple strong  \n",
       "0         0         0     0      0      0  \n",
       "1         0         0     0      0      0  \n",
       "2         0         0     0      0      0  \n",
       "3         0         0     0      0      1  \n",
       "4         0         1     0      0      0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top250Movies = top250Movies.ix[:, 0:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now repeat the process for bottom 100\n",
    "#A function that does all of this would be preferred, but I couldn't get it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom100AdjList = []\n",
    "for x in bottom100PosTokens:\n",
    "    # each x is either a list of (word, POS tag) tuples\n",
    "    for word, pos in x:\n",
    "        if pos in ['JJ', 'JJS', 'JJR']: # feel free to add any other tags you may be looking for\n",
    "            bottom100AdjList.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottom100CommonAdj= [a for a, b in Counter(bottom100AdjList).most_common(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>other</th>\n",
       "      <th>worst</th>\n",
       "      <th>first</th>\n",
       "      <th>more</th>\n",
       "      <th>funny</th>\n",
       "      <th>many</th>\n",
       "      <th>such</th>\n",
       "      <th>least</th>\n",
       "      <th>...</th>\n",
       "      <th>worse</th>\n",
       "      <th>long</th>\n",
       "      <th>high</th>\n",
       "      <th>worth</th>\n",
       "      <th>next</th>\n",
       "      <th>second</th>\n",
       "      <th>hard</th>\n",
       "      <th>several</th>\n",
       "      <th>able</th>\n",
       "      <th>hilarious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bad, good, other, worst, first, more, funny, many, such, least, same, few, most, best, old, great, awful, only, acting, horrible, terrible, original, whole, own, better, real, much, stupid, big, special, new, sure, little, poor, wrong, low, main, last, entire, young, worse, long, high, worth, next, second, hard, several, able, hilarious]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 50 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe that places each descriptor as an index\n",
    "#We see that a top 50 adjective is the letter 't.' Not sure what the pos tagger is doing there, so we'll drop the col\n",
    "bottom100Descrip = pd.DataFrame(columns=bottom100CommonAdj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we want a dataframe that joins the Review data (movieID, 15reviews each), from above with these descriptors\n",
    "bottom100Movies = pd.DataFrame(bottom100ReviewData)\n",
    "bottom100Movies = bottom100Movies.join(bottom100Descrip)\n",
    "#We see right now it's just filled with NaN values, so we'll populate the cells in the loop below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If everything is in order call the function above\n",
    "getDescriptors(bottom100Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We need to join both of these dataframes to the original dataframes that have more info about each movie ID\n",
    "#First, though, we need to drop the 'Reviews' column because we don't need all of that text\n",
    "top250Movies.drop(['reviews'], axis =1 ,inplace=True)\n",
    "bottom100Movies.drop(['reviews'], axis =1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'movieID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-6931c9d3c45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Then we need to groupby imdbID so we can actually join the tables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Currently, the review data has 15 rows for each id, while the original movie data only has 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtop250Movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop250Movies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbottom100Movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottom100Movies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m-> 3748\u001b[0;31m                        sort=sort, group_keys=group_keys, squeeze=squeeze)\n\u001b[0m\u001b[1;32m   3749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3750\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             grouper, exclusions, obj = _get_grouper(obj, keys, axis=axis,\n\u001b[0;32m--> 345\u001b[0;31m                                                     level=level, sort=sort)\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort)\u001b[0m\n\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# df.groupby('name')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m             \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3226\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelmainzer/anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4027)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3891)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12408)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'movieID'"
     ]
    }
   ],
   "source": [
    "#Then we need to groupby imdbID so we can actually join the tables.\n",
    "#Currently, the review data has 15 rows for each id, while the original movie data only has 1\n",
    "top250MoviesCopy = top250Movies.groupby([\"movieID\"], group_keys=False, as_index=False).apply(lambda x: x.iloc[:,1:].max())\n",
    "bottom100MoviesCopy = bottom100Movies.groupby([\"movieID\"], group_keys=False, as_index=False).apply(lambda x: x.iloc[:,1:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Before we go any further, let's save these sentiment tables to their own .csv files\n",
    "top250MoviesCopy.to_csv('../../../../../01-projects/assets/06-project6-assets/data/top250Descriptors.csv', encoding='utf8', index=False)\n",
    "bottom100MoviesCopy.to_csv('../../../../../01-projects/assets/06-project6-assets/data/bottom100Descriptors.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>movieType</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt2582802</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>2014</td>\n",
       "      <td>107.0</td>\n",
       "      <td>384504.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>13092000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0047478</td>\n",
       "      <td>Seven Samurai</td>\n",
       "      <td>1954</td>\n",
       "      <td>207.0</td>\n",
       "      <td>226364.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "      <td>269061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0082971</td>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>1981</td>\n",
       "      <td>115.0</td>\n",
       "      <td>653557.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>242374454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0050212</td>\n",
       "      <td>The Bridge on the River Kwai</td>\n",
       "      <td>1957</td>\n",
       "      <td>161.0</td>\n",
       "      <td>147591.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>27200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0848228</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>143.0</td>\n",
       "      <td>980989.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1</td>\n",
       "      <td>623279547.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID                         title  year  runtime  imdbVotes  \\\n",
       "0  tt2582802                      Whiplash  2014    107.0   384504.0   \n",
       "1  tt0047478                 Seven Samurai  1954    207.0   226364.0   \n",
       "2  tt0082971       Raiders of the Lost Ark  1981    115.0   653557.0   \n",
       "3  tt0050212  The Bridge on the River Kwai  1957    161.0   147591.0   \n",
       "4  tt0848228                  The Avengers  2012    143.0   980989.0   \n",
       "\n",
       "   imdbRating  movieType        gross  \n",
       "0         8.5          1   13092000.0  \n",
       "1         8.7          1     269061.0  \n",
       "2         8.5          1  242374454.0  \n",
       "3         8.2          1   27200000.0  \n",
       "4         8.1          1  623279547.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top250.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goodMovies = top250.join(top250Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "\n",
    "- What are the top 10 grossing movies?\n",
    "- Who are the 10 actors that appear in the most movies?\n",
    "- What's the average grossing of the movies in which each of these actors appear?\n",
    "- What genre is the oldest movie?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
